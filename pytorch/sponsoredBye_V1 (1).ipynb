{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch;\n",
    "import torch.nn as nn;\n",
    "import torch.nn.functional as F;\n",
    "from sentence_transformers import SentenceTransformer;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_model = SentenceTransformer('t5-base', device='cuda')\n",
    "sent_model = SentenceTransformer('sentence-transformers/sentence-t5-base', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(x, input_dim=1682):\n",
    "        encoding = sent_model.encode(x)\n",
    "        t = torch.from_numpy(encoding)\n",
    "        pad_size = input_dim - t.size(0)\n",
    "        padded_tensor = F.pad(t, (0, 0, 0, pad_size))\n",
    "        return padded_tensor\n",
    "\n",
    "embedding = embed([\"This is a warning\", \"And this is one too\", \"this is some more\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sponsoredBye(nn.Module):\n",
    "    def __init__(self, model, embedding_dim=768, inp=1682, hidden_dim=128, output_dim=2):\n",
    "        super().__init__()\n",
    "        self.device = 'cuda'\n",
    "        self.input_dim = inp\n",
    "        self.sentence_transformer = model\n",
    "        # Add padding\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=2, \n",
    "                           bidirectional=True, \n",
    "                           dropout=0.2,\n",
    "                           batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "        # Set the embedding model to not be trainable\n",
    "        for param in self.sentence_transformer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def embed(self, x):\n",
    "        encoding = self.sentence_transformer.encode(x)\n",
    "        t = torch.from_numpy(encoding).to(self.device)\n",
    "        pad_size = self.input_dim - t.size(0)\n",
    "        padded_tensor = F.pad(t, (0, 0, 0, pad_size)).to(self.device)\n",
    "        return padded_tensor\n",
    "\n",
    "    def forward(self, x):\n",
    "#         embedded = self.embed(x)\n",
    "#         a = embedded.unsqueeze(0)\n",
    "        outputs, (hidden, cell) = self.lstm(x)\n",
    "        predictions = self.fc(self.dropout(outputs))\n",
    "        x = self.softmax(predictions)\n",
    "#         y = torch.argmax(x, dim=2)\n",
    "        return x\n",
    "\n",
    "model = sponsoredBye(sent_model)\n",
    "model.to('cuda');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,315,330 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105it [00:20,  5.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a test dataset\n",
    "from pymongo import MongoClient\n",
    "from tqdm import tqdm\n",
    "\n",
    "cnt = 0\n",
    "dataset_size = 100\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "client = MongoClient(\"mongodb://49.13.173.177:27020/\")\n",
    "cursor = client.sponsoredbye.clean.find({}, {'new_clean': 1, 'new_labels': 1})\n",
    "for elem in tqdm(cursor):\n",
    "    if cnt >= dataset_size:\n",
    "        break\n",
    "    if type(elem['new_clean']) is not str:\n",
    "        continue\n",
    "    if type(elem['new_labels']) is not list:\n",
    "        continue\n",
    "    sentences.append(elem['new_clean'].replace(\". \", \"<k>\").replace(\"? \", \"<k>\").split(\"<k>\"))\n",
    "    labels.append(elem['new_labels'])\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = [(x,y) for x,y in zip(sentences, labels) if len(x) == len(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [x[0] for x in end]\n",
    "labels = [x[1] for x in end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, sentences, labels):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sentence, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sentences, labels = zip(*batch)\n",
    "    \n",
    "    # Encode sentences using the SentenceTransformer model\n",
    "    encoded_sentences = [model.sentence_transformer.encode(sentence) for sentence in sentences]\n",
    "\n",
    "    # Find the longest encoded sentence in the batch\n",
    "    max_len = max([encoding.shape[0] for encoding in encoded_sentences])\n",
    "\n",
    "    # Pad sentences to the same length\n",
    "    padded_sentences = []\n",
    "    padded_labels = []\n",
    "    for encoding, label in list(zip(encoded_sentences, labels)):\n",
    "        tensor_encoding = torch.tensor(encoding, dtype=torch.float)\n",
    "        pad_size = max_len - tensor_encoding.size(0)\n",
    "        padded_tensor = F.pad(tensor_encoding, (0, 0, 0, pad_size))\n",
    "        padded_sentences.append(padded_tensor)\n",
    "        \n",
    "        padded_tensor_l = F.pad(label, (0, pad_size))\n",
    "        padded_labels.append(padded_tensor_l)\n",
    "        \n",
    "    \n",
    "    # Stack sentences into a tensor\n",
    "    sentences_tensor = torch.stack(padded_sentences)\n",
    "    # Convert labels to tensor\n",
    "#     print(labels)\n",
    "    labels_tensor = torch.stack(padded_labels)\n",
    "    \n",
    "    return sentences_tensor, labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextDataset(sentences, labels)\n",
    "\n",
    "# Create the DataLoader with the custom collate function\n",
    "dataloader = DataLoader(dataset, batch_size=50, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6847\n",
      "Epoch [1/10], Loss: 0.6550\n",
      "Epoch [2/10], Loss: 0.6320\n",
      "Epoch [2/10], Loss: 0.6078\n",
      "Epoch [3/10], Loss: 0.5798\n",
      "Epoch [3/10], Loss: 0.5362\n",
      "Epoch [4/10], Loss: 0.5055\n",
      "Epoch [4/10], Loss: 0.4955\n",
      "Epoch [5/10], Loss: 0.4619\n",
      "Epoch [5/10], Loss: 0.3857\n",
      "Epoch [6/10], Loss: 0.3992\n",
      "Epoch [6/10], Loss: 0.3961\n",
      "Epoch [7/10], Loss: 0.3739\n",
      "Epoch [7/10], Loss: 0.4150\n",
      "Epoch [8/10], Loss: 0.3926\n",
      "Epoch [8/10], Loss: 0.4075\n",
      "Epoch [9/10], Loss: 0.4251\n",
      "Epoch [9/10], Loss: 0.3792\n",
      "Epoch [10/10], Loss: 0.4115\n",
      "Epoch [10/10], Loss: 0.3707\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Initialize the optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        s_f, l_f = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        s_f, l_f = s_f.to(\"cuda\"), l_f.to(\"cuda\")\n",
    "\n",
    "        outputs = model(s_f)\n",
    "#         print(f\"Model output dimension: {outputs.shape}, Label dimension: {l_f.shape}\")\n",
    "\n",
    "        loss = criterion(outputs.view(-1, outputs.size(-1)), l_f.view(-1)) \n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\"Welcome to my new youtrube video\", \"this video is sponsored by\", \"raid shadow legends\",\"lets get back into the video\", \"pokemon is a wild phenomenon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(model.forward(model.embed(example))[:5], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'poll'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I polli',\n",
       " ' sono animali domestici',\n",
       " ' A loro piace cantare',\n",
       " ' ma sono carini',\n",
       " '']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
